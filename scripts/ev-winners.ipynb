{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b209f81-8274-4662-8190-fc4f42cc9d66",
   "metadata": {},
   "source": [
    "I'm currently using this notebook to transform the CSV data (which comes from a Google Sheet) into: (1) A new CSV with an embedding vector added (based on the 'description' column); (2) a JSON blob to be used elsewhere. I just hit \"run all cells\" to do this. Eventually I'll just put the key steps in a Python script, but right now I'm finding it useful to be able to inspect the outputs because it's changing so much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed3e51c-28f6-4a14-88c0-c4d15822e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60161ccb-22c2-4bcc-a39e-2148fdef16e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                                               name batch  \\\n",
      "0  1.0                                          Anonymous     1   \n",
      "1  2.0                                        Topos House     1   \n",
      "2  3.0                      18-year-old economics prodigy     1   \n",
      "3  4.0  Mark Lutter and his Center for Innovative Gove...     1   \n",
      "4  5.0                                     Harshita Arora     1   \n",
      "\n",
      "  date_announced                                               link  \\\n",
      "0     2018-11-07  marginalrevolution.com/marginalrevolution/2018...   \n",
      "1     2018-11-07  marginalrevolution.com/marginalrevolution/2018...   \n",
      "2     2018-11-07  marginalrevolution.com/marginalrevolution/2018...   \n",
      "3     2018-11-07  marginalrevolution.com/marginalrevolution/2018...   \n",
      "4     2018-11-07  marginalrevolution.com/marginalrevolution/2018...   \n",
      "\n",
      "                                         description              type  \\\n",
      "0    Anonymous grant for writing in Eastern Europe.   Writing (Online)   \n",
      "1  Pledged grant to San Francisco’s Topos House, ...        Non profit   \n",
      "2  Travel grant made to 18-year-old economics pro...            Travel   \n",
      "3  Grant to support the work of Mark Lutter and h...        Non profit   \n",
      "4  Grant to Harshita Arora to help her pursue wor...          Research   \n",
      "\n",
      "  career_stage                                     personal_links  \\\n",
      "0          NaN                                                  -   \n",
      "1          NaN                                                  -   \n",
      "2  High school                                                  -   \n",
      "3       Middle  linkedin.com/in/mark-lutter-a23a7669/\\ntwitter...   \n",
      "4  High school  twitter.com/aroraharshita33\\nlinkedin.com/in/h...   \n",
      "\n",
      "                                       personal_info  \\\n",
      "0                                                  -   \n",
      "1                                                  -   \n",
      "2                                                  -   \n",
      "3  Washington\\nFounder and Executive Director at ...   \n",
      "4  San-Francisco, California\\nCo-founder of AtoB,...   \n",
      "\n",
      "                                            mr_posts         project_links  \n",
      "0                                                  -                     -  \n",
      "1                                                  -  retreat.topos.house/  \n",
      "2                                                  -                     -  \n",
      "3  marginalrevolution.com/marginalrevolution/2020...       marklutter.com/  \n",
      "4  marginalrevolution.com/marginalrevolution/2020...    harshitaarora.com/  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file_path' with the actual path to your CSV file\n",
    "df = pd.read_csv('../data/ev-winners.csv')\n",
    "\n",
    "# This will display the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e06cb5-e609-448f-93de-ff2861d28952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05316222  0.08313879 -0.00018972 ... -0.02911166 -0.05182787\n",
      "  -0.04559411]\n",
      " [ 0.00656217  0.01479886 -0.01363882 ... -0.01856913 -0.10103376\n",
      "   0.02289294]\n",
      " [ 0.08496379  0.05712386 -0.01860134 ...  0.05476078 -0.00237706\n",
      "  -0.04405489]\n",
      " ...\n",
      " [-0.02717686  0.03089065  0.02796888 ... -0.02674641 -0.01135708\n",
      "   0.06989009]\n",
      " [-0.08260766  0.05114881  0.00184061 ...  0.00910514 -0.02419201\n",
      "   0.00591901]\n",
      " [-0.01491736  0.01335617 -0.06053676 ... -0.11592133  0.08571236\n",
      "  -0.04570728]]\n"
     ]
    }
   ],
   "source": [
    "names = df['name'].to_numpy()\n",
    "descriptions = df['description'].to_numpy()\n",
    "# generate embeddings of the descriptions\n",
    "embeddings = model.encode(descriptions)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f56dafe-bb97-421d-b766-8bfd33b125c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with embeddings has been saved to '../data/ev-winners-with-embeddings.csv'\n"
     ]
    }
   ],
   "source": [
    "# Write new dataset\n",
    "\n",
    "df['embedding_description'] = embeddings.tolist()\n",
    "output_csv_path = '../data/ev-winners-with-embeddings.csv'\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"DataFrame with embeddings has been saved to '{output_csv_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804ee34c-9c83-44e9-91a1-324e0492272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_ev_winners(query):\n",
    "\n",
    "    #embeddings of the query, same dimensions as the description embeddings\n",
    "    query_embed = np.tile(model.encode(query), (len(embeddings), 1))\n",
    "    \n",
    "    cos_sim = util.cos_sim(embeddings, query_embed)\n",
    "    cos_sim\n",
    "    \n",
    "    # Add all pairs to a list with their cosine similarity score\n",
    "    all_sentence_combinations = []\n",
    "    for i in range(len(cos_sim)-1):\n",
    "        all_sentence_combinations.append([cos_sim[i], descriptions[i], names[i]])\n",
    "    \n",
    "    # Sort list by the highest cosine similarity score\n",
    "    all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0][0], reverse=True)\n",
    "    \n",
    "    return all_sentence_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "421f05e4-9c03-4701-9fac-6d7d300c18a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 matches for query: book\n",
      "\n",
      "1. Andy Matuschak: San Francisco, to support his project to reexamine and fundamentally improve the book as a method for learning and absorbing ideas, Twitter here. Here is his essay on why books do not work.\n",
      "2. Jeremy Stern: Glendale, CA, Tablet magazine. To write a book.\n",
      "3. Jasmine Wang and team (Jasmine is a repeat winner): Trellis, AI and the book.\n",
      "4. Marc Sidwell: Marc Sidwell of the United Kingdom, to write a book on common sense.\n",
      "5. Henry Oliver: Henry Oliver, London, to write a book on talent and late bloomers. Substack here.\n",
      "6. Byrne Hobart: Byrne Hobart, to write a book on technological progress with Tobias Huber.\n",
      "7. Jeffrey C. Huber: Jeffrey C. Huber, to write a book on tech and economic progress from a Christian point of view.\n",
      "8. Matt Faherty: Matt Faherty, to study and write about the NIH.\n",
      "9. Yuen Yuen Ang: Yuen Yuen Ang, political scientist at the University of Michigan, from Singapore, to write a new book on disruption.\n",
      "10. Kathleen Harward: Kathleen Harward, to write and market a series of children’s books based on classical liberal values.\n"
     ]
    }
   ],
   "source": [
    "def search_ev_winners(query, number):\n",
    "    print(f\"Top {number} matches for query: {query}\\n\")\n",
    "    for index, item in enumerate(get_ev_winners(query)[:number], start=1):\n",
    "        print(f\"{index}. {item[2]}: {item[1]}\")\n",
    "\n",
    "search_ev_winners(\"book\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86842b34-5362-4ad2-939a-fcac0126908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON blob has been saved to '../data/ev-winners-with-embeddings.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON blob\n",
    "df2 = pd.read_csv('../data/ev-winners-with-embeddings.csv')\n",
    "df2['embedding_description'] = df2['embedding_description'].apply(json.loads)\n",
    "json_blob = df2.to_json(orient='records', lines=False)\n",
    "output_json_path = '../data/ev-winners-with-embeddings.json'\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json_file.write(json_blob)\n",
    "print(f\"JSON blob has been saved to '{output_json_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85081543-cd9f-4985-83f4-cde0078e8096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_5_records = json_blob.split('\\n')[:5]\n",
    "\n",
    "import json\n",
    "\n",
    "# Your JSON data as a string\n",
    "json_string = first_5_records[0]\n",
    "\n",
    "# Parse the JSON string into a JSON object\n",
    "json_data = json.loads(json_string)\n",
    "\n",
    "# Pretty print the JSON object\n",
    "pretty_json = json.dumps(json_data, indent=4)\n",
    "\n",
    "# Print the pretty printed JSON\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3a872-0f67-49e0-8a7b-b208ed64bb05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
